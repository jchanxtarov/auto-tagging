{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('3.7.9')",
   "metadata": {
    "interpreter": {
     "hash": "827a7b17119d355de220ab7e398528664ea93d3a85ef543eb44860a7302b2fea"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# !pip install pyspark\n",
    "# !pip install selenium\n",
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "from functions import prepare_image, extract_features\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib import tzip\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "source": [
    "# Data Loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snaps_women = pd.read_csv('datasets/snaps1k_women.csv')\n",
    "print(df_snaps_women.columns)\n",
    "\n",
    "df_snaps_women = df_snaps_women[['snap_id', 'image_url', 'tags_selected']]\n",
    "df_snaps_women.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_snaps = set(list(df_snaps_women['snap_id']))\n",
    "dict_snap2id = {snap: idx for idx, snap in enumerate(list_snaps)}\n",
    "\n",
    "list_tags = [eval(t) for t in list(df_snaps_women['tags_selected'])]\n",
    "tags_flatten = list(itertools.chain.from_iterable(list_tags))\n",
    "dict_tag2count = collections.Counter(tags_flatten)\n",
    "df_tag2count = pd.DataFrame({'tag': list(dict_tag2count.keys()), 'count': list(dict_tag2count.values())})\n",
    "df_tag2count = df_tag2count.sort_values('count')\n",
    "\n",
    "print(\"count uniq tags : %d\" % len(df_tag2count))\n",
    "idxs = list(df_tag2count.index)\n",
    "tags = list(df_tag2count['tag'])\n",
    "dict_tag2id = {tag: idx for idx, tag in zip(idxs, tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tagids = []\n",
    "list_snapids = []\n",
    "\n",
    "for snap, tags in zip(list_snaps, list_tags):\n",
    "    for tag in tags:\n",
    "        list_tagids.append(dict_tag2id[tag])\n",
    "        list_snapids.append(dict_snap2id[snap])\n",
    "\n",
    "hashtag_rec_data = pd.DataFrame({\n",
    "    'hashtag_id': list_tagids,\n",
    "    'image_id': list_snapids,\n",
    "    'rating': 1})\n",
    "hashtag_rec_data.tail()"
   ]
  },
  {
   "source": [
    "# Load Pre-trained Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (160, 160, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "neural_network = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = []\n",
    "for snap, tags in tzip(list_snaps, list_tags):\n",
    "    img_path = f'data/women_images/{snap}.png'\n",
    "    try:\n",
    "        img = prepare_image(img_path, where='local')\n",
    "        deep_features = extract_features(img, neural_network)\n",
    "        pics.append({'pic': img, \n",
    "                     'hashtags': tags,\n",
    "                     'deep_features': deep_features})\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if error_type == \"NotFoundError\":\n",
    "            # If a file in the list isn't in \n",
    "            # storage, skip it and continue\n",
    "            pass\n",
    "        else:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = pd.DataFrame(pics)\n",
    "pics['image_id'] = [dict_snap2id[idx] for idx in list(df_snaps_women['snap_id'])]\n",
    "pics.head()"
   ]
  },
  {
   "source": [
    "# Checking sample picture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = pics.iloc[20] \n",
    "print(type(pic['pic']))\n",
    "print(pic['hashtags'], pic['deep_features'].shape, pic['pic'].shape)\n",
    "plt.imshow(pic['pic'])"
   ]
  },
  {
   "source": [
    "# Load ALS Collaborative filtering model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get update\n",
    "# !sudo apt-get install openjdk-11-jdk\n",
    "# !java --version\n",
    "# !export JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('local').getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "als = ALS(userCol='image_id',\n",
    "          itemCol='hashtag_id',\n",
    "          ratingCol=\"rating\",\n",
    "          implicitPrefs=True,\n",
    "          alpha=40)\n",
    "als.setSeed(0)\n",
    "\n",
    "hashtag_spark_df = spark.createDataFrame(hashtag_rec_data)\n",
    "als_model = als.fit(hashtag_spark_df)\n",
    "# als_model.write().overwrite().save('als')\n",
    "\n",
    "recs = als_model.recommendForAllUsers(numItems=10).toPandas()\n",
    "recs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_index = list(dict_tag2id.keys())\n",
    "def lookup_hashtag_recs(rec_scores):\n",
    "    return [hashtag_index(rec_tagid) for (rec_tagid, score) in rec_scores]\n",
    "\n",
    "recs['recommended_hashtags'] = recs['recommendations'].apply(lookup_hashtag_recs)\n",
    "df_snaps_women['image_id'] = [dict_snap2id[idx] for idx in list(df_snaps_women['snap_id'])]\n",
    "recs = pd.merge(recs, df_snaps_women, on='image_id')\n",
    "recs.head(3)"
   ]
  },
  {
   "source": [
    "# merge image features (cf)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recs.drop('recommendations', axis=1, inplace=True)\n",
    "image_factors = als_model.userFactors.toPandas()\n",
    "image_factors['image_id'] = image_factors['id']\n",
    "recs = pd.merge(recs, image_factors, on='image_id')\n",
    "recs.head(3)"
   ]
  },
  {
   "source": [
    "# merge image features (cnn)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics['image_id'] = [dict_snap2id[idx] for idx in list(df_snaps_women['snap_id'])]\n",
    "recs_deep = pd.merge(recs, pics, on='image_id', how='inner')\n",
    "recs_deep.info()"
   ]
  },
  {
   "source": [
    "# uniq hashtag list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recs.loc[0, 'image_id'])\n",
    "print(len(dict_tag2id), type(dict_tag2id))\n",
    "\n",
    "hashtags_df = pd.DataFrame.from_dict(dict_tag2id, orient='index')\n",
    "hashtags_df = hashtags_df.reset_index()\n",
    "hashtags_df.columns = ['hashtag', 'id']\n",
    "hashtags_df.index = hashtags_df['id']\n",
    "hashtags_df.drop('id', axis=1, inplace=True)\n",
    "hashtags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_features = als_model.itemFactors.toPandas()  # tag に関するCF特徴量\n",
    "image_features = als_model.userFactors.toPandas()  # image に関するCF特徴量\n",
    "\n",
    "# Only use certain columns\n",
    "recommender_df = recs_deep[[\n",
    "    'image_id', # image_id\n",
    "    'hashtags', # hashtags\n",
    "    'deep_features', # deep_features\n",
    "    'features', # als_features\n",
    "]]\n",
    "recommender_df.head()"
   ]
  },
  {
   "source": [
    "# Searching hashtags for test image\n",
    "\n",
    "1. deep_features で cosine similarity が近い５件の画像を取ってくる\n",
    "2. その５件の画像に関する als_features (tag x image の collaborative filtering の結果の image_features)を取ってきて，平均をとる(avg_features)\n",
    "3. 全タグのCF特徴量について， 2 の avg_features (画像特徴量上位5件の，CF特徴量に関する平均)との内積を計算\n",
    "4. 上位１０件のタグを取得してくる\n",
    "\n",
    "**要するに，ターゲット画像と画像特徴量が似ている５件の画像に関するCF特徴量の平均と，CF特徴量が類似しているハッシュタグを１０件取得してくる（ハッシュタグと画像は同一空間に写像しているものとしている）**\n",
    "\n",
    "- Alternating Least Squares (ALS): http://mogile.web.fc2.com/spark/ml-collaborative-filtering.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that finds k nearest neighbors by cosine similarity\n",
    "def find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df):\n",
    "    # Find image features (user vectors) for similar images.\n",
    "    prep_image = prepare_image(image_path, where='local')\n",
    "    pics = extract_features(prep_image, neural_network)\n",
    "    rdf = recommender_df.copy()\n",
    "    rdf['dist'] = rdf['deep_features'].apply(lambda x: cosine(x, pics))\n",
    "    rdf = rdf.sort_values(by='dist')\n",
    "    return rdf.head(k)\n",
    "\n",
    "def generate_hashtags(image_path):\n",
    "    # 1. deep_features で cosine similarity が近い５件の画像を取ってくる\n",
    "    fnv = find_neighbor_vectors(image_path, k=5, recommender_df=recommender_df)\n",
    "    \n",
    "    # 2. その５件の画像に関する als_features (tag x image の collaborative filtering の結果の image_features)を取ってきて，平均をとる(avg_features)\n",
    "    features = []\n",
    "    for item in fnv.features.values:\n",
    "        features.append(item)\n",
    "    avg_features = np.mean(np.asarray(features), axis=0)\n",
    "    \n",
    "    # 3. 全タグのCF特徴量について， 2 の avg_features (画像特徴量上位5件の，CF特徴量に関する平均)との内積を計算\n",
    "    hashtag_features['dot_product'] = hashtag_features['features'].apply(lambda x: np.asarray(x).dot(avg_features))\n",
    "\n",
    "    # 4. 上位１０件のタグを取得してくる\n",
    "    final_recs = hashtag_features.sort_values(by='dot_product', ascending=False).head(10)\n",
    "    print(\"final_recs: \", final_recs)\n",
    "    print(\"final_recs.id.values: \", final_recs.id.values)\n",
    "    output = []\n",
    "    for hashtag_id in final_recs.id.values:\n",
    "        output.append(hashtags_df.iloc[hashtag_id]['hashtag'])\n",
    "    return output\n",
    "\n",
    "def show_results(test_image):\n",
    "    img = mpimg.imread(f'data/women_images/{test_image}.png')\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.title(f'Original Hashtag: {test_image.upper()}', fontsize=32)        \n",
    "    plt.imshow(img)\n",
    "    \n",
    "    recommended_hashtags = generate_hashtags(f'data/women_images/{test_image}.png')\n",
    "    print(', '.join(recommended_hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results('17658876')"
   ]
  }
 ]
}